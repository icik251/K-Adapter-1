{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNModel(\n",
       "  (lstm): LSTM(768, 256, num_layers=2, batch_first=True)\n",
       "  (linear_layers): Sequential(\n",
       "    (0): ReLU()\n",
       "    (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "# a = torch.Tensor([1, 2, 3,5,6])\n",
    "# b = torch.Tensor([1, 2, 3])\n",
    "\n",
    "# print(a + b)\n",
    "\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.input_size = 768\n",
    "        self.hidden_size = 256\n",
    "        self.num_layers = 2\n",
    "        self.num_classes = 1\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            self.input_size, self.hidden_size, self.num_layers, batch_first=True\n",
    "        )\n",
    "\n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, self.num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(\"cuda\")\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(\"cuda\")\n",
    "\n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(\n",
    "            x, (h0, c0)\n",
    "        )  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.linear_layers(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "\n",
    "rnn_model = RNNModel()\n",
    "rnn_model.to(\"cuda\")\n",
    "\n",
    "# x = torch.randn(1, 1, 768)\n",
    "# y = rnn_model(x)\n",
    "# from torchviz import make_dot\n",
    "# make_dot(y.mean(), params=dict(rnn_model.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------\n",
      "      Layer (type)                               Input Shape         Param #     Tr. Param #\n",
      "=============================================================================================\n",
      "            LSTM-1     [1, 1, 768], [2, 1, 256], [2, 1, 256]       1,576,960       1,576,960\n",
      "            ReLU-2                                  [1, 256]               0               0\n",
      "          Linear-3                                  [1, 256]          32,896          32,896\n",
      "         Dropout-4                                  [1, 128]               0               0\n",
      "            ReLU-5                                  [1, 128]               0               0\n",
      "          Linear-6                                  [1, 128]             129             129\n",
      "=============================================================================================\n",
      "Total params: 1,609,985\n",
      "Trainable params: 1,609,985\n",
      "Non-trainable params: 0\n",
      "---------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from pytorch_model_summary import summary\n",
    "x = torch.randn(1, 1, 768).to('cuda')\n",
    "print(summary(rnn_model, x, show_input=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------\n",
      "      Layer (type)                              Output Shape         Param #     Tr. Param #\n",
      "=============================================================================================\n",
      "            LSTM-1     [1, 1, 256], [2, 1, 256], [2, 1, 256]       1,576,960       1,576,960\n",
      "            ReLU-2                                  [1, 256]               0               0\n",
      "          Linear-3                                  [1, 128]          32,896          32,896\n",
      "         Dropout-4                                  [1, 128]               0               0\n",
      "            ReLU-5                                  [1, 128]               0               0\n",
      "          Linear-6                                    [1, 1]             129             129\n",
      "=============================================================================================\n",
      "Total params: 1,609,985\n",
      "Trainable params: 1,609,985\n",
      "Non-trainable params: 0\n",
      "---------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "============================ Hierarchical Summary ============================\n",
      "\n",
      "RNNModel(\n",
      "  (lstm): LSTM(768, 256, num_layers=2, batch_first=True), 1,576,960 params\n",
      "  (linear_layers): Sequential(\n",
      "    (0): ReLU(), 0 params\n",
      "    (1): Linear(in_features=256, out_features=128, bias=True), 32,896 params\n",
      "    (2): Dropout(p=0.2, inplace=False), 0 params\n",
      "    (3): ReLU(), 0 params\n",
      "    (4): Linear(in_features=128, out_features=1, bias=True), 129 params\n",
      "  ), 33,025 params\n",
      "), 1,609,985 params\n",
      "\n",
      "\n",
      "==============================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pytorch_model_summary import summary\n",
    "x = torch.randn(1, 1, 768).to('cuda')\n",
    "print(summary(rnn_model, x, show_hierarchical=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a906de04c7a0b2b90bb0d0b019b3e4cd4e7cfd3be1f1e01d099e632a17993ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
